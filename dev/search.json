[
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "CCBR Tools",
    "section": "",
    "text": "fix: don’t add extra newline to command stdout/stderr for shell_run() and exec_in_context(). (#10, @kelly-sovacool)"
  },
  {
    "objectID": "CHANGELOG.html#tools-development-version",
    "href": "CHANGELOG.html#tools-development-version",
    "title": "CCBR Tools",
    "section": "",
    "text": "fix: don’t add extra newline to command stdout/stderr for shell_run() and exec_in_context(). (#10, @kelly-sovacool)"
  },
  {
    "objectID": "CHANGELOG.html#tools-0.1.0",
    "href": "CHANGELOG.html#tools-0.1.0",
    "title": "CCBR Tools",
    "section": "Tools 0.1.0",
    "text": "Tools 0.1.0\nThe Tools repository is now restructured as a Python package. All previous python scripts which included command line utilities have been moved to src/, and all other scripts have been moved to scripts/. In both cases, they are available in the path when the package is installed.\nFunctions which were part of both XAVIER and RENEE are available for re-use in other bioinformatics pipelines for tasks such as determining the HPC environment, retrieving available genome annotations, and printing citation and version information. Explore the ccbr_tools reference documentation for more information: https://ccbr.github.io/Tools/latest/reference/\n\nCLI Utilities\nCommand-line utilities in CCBR Tools.\n\nccbr_tools\ngb2gtf\nhf\nintersect\njobby\njobinfo\npeek\n\nRun a command with --help to learn how to use it.\n\n\nExternal Scripts\nAdditional standalone scripts for various common tasks in scripts/ are added to the path when this package is installed. They are less robust than the CLI Utilities included in the package and do not have any unit tests.\n\nadd_gene_name_to_count_matrix.R\naggregate_data_tables.R\nargparse.bash\ncancel_snakemake_jobs.sh\ncreate_hpc_link.sh\nextract_value_from_json.py\nextract_value_from_yaml.py\nfilter_bam_by_readids.py\nfilter_fastq_by_readids_highmem.py\nfilter_fastq_by_readids_highmem_pe.py\ngather_cluster_stats.sh\ngather_cluster_stats_biowulf.sh\nget_buyin_partition_list.bash\nget_slurm_file_with_error.sh\ngsea_preranked.sh\nkaryoploter.R\nmake_labels_for_pipeliner.sh\nrawcounts2normalizedcounts_DESeq2.R\nrawcounts2normalizedcounts_limmavoom.R\nrun_jobby_on_nextflow_log\nrun_jobby_on_nextflow_log_full_format\nrun_jobby_on_snakemake_log\nrun_jobby_on_snakemake_log_full_format\nspooker\nwhich_vpn.sh"
  },
  {
    "objectID": "CHANGELOG.html#tools-0.0.1",
    "href": "CHANGELOG.html#tools-0.0.1",
    "title": "CCBR Tools",
    "section": "Tools 0.0.1",
    "text": "Tools 0.0.1\nThis tag marks the repository state from before refactoring it as a python package."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "jobby\nDisplay job information for past slurm job IDs\n\n\npeek\nTake a peek at tab-delimited files\n\n\npipeline\n\n\n\npkg_util\nMiscellaneous utility functions for the package\n\n\nshell\nUtility functions for shell command execution.",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#modules",
    "href": "reference/index.html#modules",
    "title": "Function reference",
    "section": "",
    "text": "jobby\nDisplay job information for past slurm job IDs\n\n\npeek\nTake a peek at tab-delimited files\n\n\npipeline\n\n\n\npkg_util\nMiscellaneous utility functions for the package\n\n\nshell\nUtility functions for shell command execution.",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/jobby.html",
    "href": "reference/jobby.html",
    "title": "jobby",
    "section": "",
    "text": "jobby\nDisplay job information for past slurm job IDs\n\n\njobby will take your past jobs and display their job information. Why? We have pipelines running on several different clusters and job schedulers. jobby is an attempt to centralize and abstract the process of querying different job schedulers. On each supported target system, jobby will attempt to determine the best method for getting job information to return to the user in a standardized format and unified cli.\nMany thanks to the original author: Skyler Kuhn (@skchronicles)\nOriginal source: https://raw.githubusercontent.com/OpenOmics/mr-seek/2ecbbb2628b7102bf2cc23bc946858de2e09929f/workflow/scripts/jobby\n\n\n\n\npython&gt;=3.5\n\n\n\n\nPUBLIC DOMAIN NOTICE\n        NIAID Collaborative Bioinformatics Resource (NCBR)\n\n   National Institute of Allergy and Infectious Diseases (NIAID)\nThis software/database is a \"United  States Government Work\" under\nthe terms of the United  States Copyright Act.  It was written as\npart of the author's official duties as a United States Government\nemployee and thus cannot be copyrighted. This software is freely\navailable to the public for use.\n\nAlthough all  reasonable  efforts have been taken  to ensure  the\naccuracy and reliability of the software and data, NCBR do not and\ncannot warrant the performance or results that may  be obtained by\nusing this software or data. NCBR and NIH disclaim all warranties,\nexpress  or  implied,  including   warranties   of   performance,\nmerchantability or fitness for any particular purpose.\n\nPlease cite the author and NIH resources like the \"Biowulf Cluster\"\nin any work or product based on this material.\n\n\n\n$ jobby [OPTIONS] JOB_ID [JOB_ID …]\n\n\n\n$ jobby 18627545 15627516 58627597\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nColors\nClass encoding for ANSI escape sequences for styling terminal text.\n\n\n\n\n\njobby.Colors()\nClass encoding for ANSI escape sequences for styling terminal text. Any string that is formatting with these styles must be terminated with the escape sequence, i.e. Colors.end.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_missing\nAdds missing information to a list. This can be used\n\n\nconvert_size\nConverts bytes to a human readable format.\n\n\ndashboard_cli\nBiowulf-specific tool to get SLURM job information.\n\n\nerr\nPrints any provided args to standard error.\n\n\nfatal\nPrints any provided args to standard error\n\n\nget_toolkit\nFinds the best suited tool from a list of\n\n\njobby\nWrapper to each supported job scheduler: slurm, etc.\n\n\nparsed_arguments\nParses user-provided command-line arguments. This requires\n\n\nsacct\nGeneric tool to get SLURM job information.\n\n\nsge\nDisplays SGE job information to standard output.\n\n\nslurm\nDisplays SLURM job information to standard output.\n\n\nto_bytes\nConvert a human readable size unit into bytes.\n\n\nuge\nDisplays UGE job information to standard output.\n\n\nwhich\nChecks if an executable is in $PATH\n\n\n\n\n\njobby.add_missing(linelist, insertion_dict)\nAdds missing information to a list. This can be used to add missing job information fields to the results of job querying tool. @param linelist list[]: List containing job information for each field of interest @param insertion_dict dict[] = str Dictionary used to insert missing information to a given index, where the keys are indices of the linelist and the values are information to add. Please note that the indices should be zero based. Note that multiple consecutive values should be inserted at once as a list, see example below: Example: add_missing([0,1,2,3,4], {3:[‘+’,‘++’], 1:‘-’, 4:‘@’}) &gt;&gt; [0, ‘-’, 1, 2, ‘+’, ‘++’, 3, ‘@’, 4]\n\n\n\njobby.convert_size(size_bytes)\nConverts bytes to a human readable format.\n\n\n\njobby.dashboard_cli(jobs, threads=1, tmp_dir=None)\nBiowulf-specific tool to get SLURM job information. HPC staff recommend using this over the default slurm sacct command for performance reasons. By default, the dashboard_cli returns information for the following fields: jobid state submit_time partition nodes cpus mem timelimit gres dependency queued_time state_reason start_time elapsed_time end_time cpu_max mem_max eval Runs command: $ dashboard_cli jobs\n–joblist 12345679,12345680\n–fields FIELD,FIELD,FIELD\n–tab –archive\n\n\n\njobby.err(*message, **kwargs)\nPrints any provided args to standard error. kwargs can be provided to modify print functions behavior. @param message : Values printed to standard error @params kwargs &lt;print()&gt; Key words to modify print function behavior\n\n\n\njobby.fatal(*message, **kwargs)\nPrints any provided args to standard error and exits with an exit code of 1. @param message : Values printed to standard error @params kwargs &lt;print()&gt; Key words to modify print function behavior\n\n\n\njobby.get_toolkit(tool_list)\nFinds the best suited tool from a list of possible choices. Assumes tool list is already ordered from the best to worst choice. The first tool found in a user’s $PATH is returned. @param tool_list list[]: List of ordered tools to find @returns best_choice : First tool found in tool_list\n\n\n\njobby.jobby(args)\nWrapper to each supported job scheduler: slurm, etc. Each scheduler has a custom handler to most effectively get and parse job information. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.parsed_arguments(name, description)\nParses user-provided command-line arguments. This requires argparse and textwrap packages. To create custom help formatting a text wrapped docstring is used to create the help message for required options. As so, the help message for require options must be suppressed. If a new required argument is added to the cli, it must be updated in the usage statement docstring below. @param name : Name of the pipeline or command-line tool @param description : Short description of pipeline or command-line tool\n\n\n\njobby.sacct(jobs, threads=1, tmp_dir=None)\nGeneric tool to get SLURM job information. sacct should be available on all SLURM clusters. The dashboard_cli is prioritized over using sacct due to perform reasons; however, this method will be portable across different SLURM clusters. To get maximum memory usage for a job, we will need to parse the MaxRSS field from the $SLURM_JOBID.batch lines. Returns job information for the following fields: jobid jobname state partition reqtres alloccpus reqmem maxrss timelimit reserved start end elapsed nodelist user workdir To get maximum memory usage for a job, we will need to parse the MaxRSS fields from the $SLURM_JOBID.batch lines. Runs command: $ sacct -j 12345679,12345680\n–fields FIELD,FIELD,FIELD\n-P –delimiter $’ ’\n\n\n\njobby.sge(jobs, threads, tmp_dir)\nDisplays SGE job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.slurm(jobs, threads, tmp_dir)\nDisplays SLURM job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.to_bytes(size)\nConvert a human readable size unit into bytes. Returns None if cannot convert/parse provided size.\n\n\n\njobby.uge(jobs, threads, tmp_dir)\nDisplays UGE job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.which(cmd, path=None)\nChecks if an executable is in $PATH @param cmd : Name of executable to check @param path : Optional list of PATHs to check [default: $PATH] @return : True if exe in PATH, False if not in PATH",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#about",
    "href": "reference/jobby.html#about",
    "title": "jobby",
    "section": "",
    "text": "jobby will take your past jobs and display their job information. Why? We have pipelines running on several different clusters and job schedulers. jobby is an attempt to centralize and abstract the process of querying different job schedulers. On each supported target system, jobby will attempt to determine the best method for getting job information to return to the user in a standardized format and unified cli.\nMany thanks to the original author: Skyler Kuhn (@skchronicles)\nOriginal source: https://raw.githubusercontent.com/OpenOmics/mr-seek/2ecbbb2628b7102bf2cc23bc946858de2e09929f/workflow/scripts/jobby",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#requires",
    "href": "reference/jobby.html#requires",
    "title": "jobby",
    "section": "",
    "text": "python&gt;=3.5",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#disclaimer",
    "href": "reference/jobby.html#disclaimer",
    "title": "jobby",
    "section": "",
    "text": "PUBLIC DOMAIN NOTICE\n        NIAID Collaborative Bioinformatics Resource (NCBR)\n\n   National Institute of Allergy and Infectious Diseases (NIAID)\nThis software/database is a \"United  States Government Work\" under\nthe terms of the United  States Copyright Act.  It was written as\npart of the author's official duties as a United States Government\nemployee and thus cannot be copyrighted. This software is freely\navailable to the public for use.\n\nAlthough all  reasonable  efforts have been taken  to ensure  the\naccuracy and reliability of the software and data, NCBR do not and\ncannot warrant the performance or results that may  be obtained by\nusing this software or data. NCBR and NIH disclaim all warranties,\nexpress  or  implied,  including   warranties   of   performance,\nmerchantability or fitness for any particular purpose.\n\nPlease cite the author and NIH resources like the \"Biowulf Cluster\"\nin any work or product based on this material.",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#usage",
    "href": "reference/jobby.html#usage",
    "title": "jobby",
    "section": "",
    "text": "$ jobby [OPTIONS] JOB_ID [JOB_ID …]",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#example",
    "href": "reference/jobby.html#example",
    "title": "jobby",
    "section": "",
    "text": "$ jobby 18627545 15627516 58627597",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#classes",
    "href": "reference/jobby.html#classes",
    "title": "jobby",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nColors\nClass encoding for ANSI escape sequences for styling terminal text.\n\n\n\n\n\njobby.Colors()\nClass encoding for ANSI escape sequences for styling terminal text. Any string that is formatting with these styles must be terminated with the escape sequence, i.e. Colors.end.",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/jobby.html#functions",
    "href": "reference/jobby.html#functions",
    "title": "jobby",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_missing\nAdds missing information to a list. This can be used\n\n\nconvert_size\nConverts bytes to a human readable format.\n\n\ndashboard_cli\nBiowulf-specific tool to get SLURM job information.\n\n\nerr\nPrints any provided args to standard error.\n\n\nfatal\nPrints any provided args to standard error\n\n\nget_toolkit\nFinds the best suited tool from a list of\n\n\njobby\nWrapper to each supported job scheduler: slurm, etc.\n\n\nparsed_arguments\nParses user-provided command-line arguments. This requires\n\n\nsacct\nGeneric tool to get SLURM job information.\n\n\nsge\nDisplays SGE job information to standard output.\n\n\nslurm\nDisplays SLURM job information to standard output.\n\n\nto_bytes\nConvert a human readable size unit into bytes.\n\n\nuge\nDisplays UGE job information to standard output.\n\n\nwhich\nChecks if an executable is in $PATH\n\n\n\n\n\njobby.add_missing(linelist, insertion_dict)\nAdds missing information to a list. This can be used to add missing job information fields to the results of job querying tool. @param linelist list[]: List containing job information for each field of interest @param insertion_dict dict[] = str Dictionary used to insert missing information to a given index, where the keys are indices of the linelist and the values are information to add. Please note that the indices should be zero based. Note that multiple consecutive values should be inserted at once as a list, see example below: Example: add_missing([0,1,2,3,4], {3:[‘+’,‘++’], 1:‘-’, 4:‘@’}) &gt;&gt; [0, ‘-’, 1, 2, ‘+’, ‘++’, 3, ‘@’, 4]\n\n\n\njobby.convert_size(size_bytes)\nConverts bytes to a human readable format.\n\n\n\njobby.dashboard_cli(jobs, threads=1, tmp_dir=None)\nBiowulf-specific tool to get SLURM job information. HPC staff recommend using this over the default slurm sacct command for performance reasons. By default, the dashboard_cli returns information for the following fields: jobid state submit_time partition nodes cpus mem timelimit gres dependency queued_time state_reason start_time elapsed_time end_time cpu_max mem_max eval Runs command: $ dashboard_cli jobs\n–joblist 12345679,12345680\n–fields FIELD,FIELD,FIELD\n–tab –archive\n\n\n\njobby.err(*message, **kwargs)\nPrints any provided args to standard error. kwargs can be provided to modify print functions behavior. @param message : Values printed to standard error @params kwargs &lt;print()&gt; Key words to modify print function behavior\n\n\n\njobby.fatal(*message, **kwargs)\nPrints any provided args to standard error and exits with an exit code of 1. @param message : Values printed to standard error @params kwargs &lt;print()&gt; Key words to modify print function behavior\n\n\n\njobby.get_toolkit(tool_list)\nFinds the best suited tool from a list of possible choices. Assumes tool list is already ordered from the best to worst choice. The first tool found in a user’s $PATH is returned. @param tool_list list[]: List of ordered tools to find @returns best_choice : First tool found in tool_list\n\n\n\njobby.jobby(args)\nWrapper to each supported job scheduler: slurm, etc. Each scheduler has a custom handler to most effectively get and parse job information. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.parsed_arguments(name, description)\nParses user-provided command-line arguments. This requires argparse and textwrap packages. To create custom help formatting a text wrapped docstring is used to create the help message for required options. As so, the help message for require options must be suppressed. If a new required argument is added to the cli, it must be updated in the usage statement docstring below. @param name : Name of the pipeline or command-line tool @param description : Short description of pipeline or command-line tool\n\n\n\njobby.sacct(jobs, threads=1, tmp_dir=None)\nGeneric tool to get SLURM job information. sacct should be available on all SLURM clusters. The dashboard_cli is prioritized over using sacct due to perform reasons; however, this method will be portable across different SLURM clusters. To get maximum memory usage for a job, we will need to parse the MaxRSS field from the $SLURM_JOBID.batch lines. Returns job information for the following fields: jobid jobname state partition reqtres alloccpus reqmem maxrss timelimit reserved start end elapsed nodelist user workdir To get maximum memory usage for a job, we will need to parse the MaxRSS fields from the $SLURM_JOBID.batch lines. Runs command: $ sacct -j 12345679,12345680\n–fields FIELD,FIELD,FIELD\n-P –delimiter $’ ’\n\n\n\njobby.sge(jobs, threads, tmp_dir)\nDisplays SGE job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.slurm(jobs, threads, tmp_dir)\nDisplays SLURM job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.to_bytes(size)\nConvert a human readable size unit into bytes. Returns None if cannot convert/parse provided size.\n\n\n\njobby.uge(jobs, threads, tmp_dir)\nDisplays UGE job information to standard output. @param sub_args &lt;parser.parse_args() object&gt;: Parsed command-line arguments @return None\n\n\n\njobby.which(cmd, path=None)\nChecks if an executable is in $PATH @param cmd : Name of executable to check @param path : Optional list of PATHs to check [default: $PATH] @return : True if exe in PATH, False if not in PATH",
    "crumbs": [
      "Reference",
      "Modules",
      "jobby"
    ]
  },
  {
    "objectID": "reference/peek.html",
    "href": "reference/peek.html",
    "title": "peek",
    "section": "",
    "text": "peek\nTake a peek at tab-delimited files\n\n\npeek &lt;file.tsv&gt; [buffer]\n\n\n\n\n\n\nName\nDescription\n\n\n\n\njustify\nCalculates the spacing for justifying to the right\n\n\nmax_string\nGiven a list of strings, finds the maximum strign length\n\n\npargs\nBasic command-line parser\n\n\npprint\nRe-formats first two lines on file so columns are left justified and values are right justified\n\n\nprint_header\nPrint filenames and divider\n\n\nusage\nPrint usage information and exit program\n\n\n\n\n\npeek.justify(h, d, n, nr)\nCalculates the spacing for justifying to the right\n\n\n\npeek.max_string(data)\nGiven a list of strings, finds the maximum strign length\n\n\n\npeek.pargs()\nBasic command-line parser\n\n\n\npeek.pprint(headlist, data, linelength, fn)\nRe-formats first two lines on file so columns are left justified and values are right justified\n\n\n\npeek.print_header(filename, length)\nPrint filenames and divider\n\n\n\npeek.usage()\nPrint usage information and exit program",
    "crumbs": [
      "Reference",
      "Modules",
      "peek"
    ]
  },
  {
    "objectID": "reference/peek.html#usage",
    "href": "reference/peek.html#usage",
    "title": "peek",
    "section": "",
    "text": "peek &lt;file.tsv&gt; [buffer]",
    "crumbs": [
      "Reference",
      "Modules",
      "peek"
    ]
  },
  {
    "objectID": "reference/peek.html#functions",
    "href": "reference/peek.html#functions",
    "title": "peek",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\njustify\nCalculates the spacing for justifying to the right\n\n\nmax_string\nGiven a list of strings, finds the maximum strign length\n\n\npargs\nBasic command-line parser\n\n\npprint\nRe-formats first two lines on file so columns are left justified and values are right justified\n\n\nprint_header\nPrint filenames and divider\n\n\nusage\nPrint usage information and exit program\n\n\n\n\n\npeek.justify(h, d, n, nr)\nCalculates the spacing for justifying to the right\n\n\n\npeek.max_string(data)\nGiven a list of strings, finds the maximum strign length\n\n\n\npeek.pargs()\nBasic command-line parser\n\n\n\npeek.pprint(headlist, data, linelength, fn)\nRe-formats first two lines on file so columns are left justified and values are right justified\n\n\n\npeek.print_header(filename, length)\nPrint filenames and divider\n\n\n\npeek.usage()\nPrint usage information and exit program",
    "crumbs": [
      "Reference",
      "Modules",
      "peek"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CCBR Tools",
    "section": "",
    "text": "Utilities for CCBR Bioinformatics Software\n   \n\n\nOn biowulf you can access the latest release of ccbr_tools by loading the ccbrpipeliner module:\nmodule load ccbrpipeliner\nOutside of biowulf, you can install the package with pip:\npip install git+https://github.com/CCBR/Tools\nOr specify a specific tagged version or branch:\npip install git+https://github.com/CCBR/Tools@v0.1.0\n\n\n\n\n\nccbr_tools --help\nUsage: ccbr_tools [OPTIONS] COMMAND [ARGS]...\n\n  Utilities for CCBR Bioinformatics Software\n\n  For more options, run: tool_name [command] --help\n\nOptions:\n  -v, --version  Show the version and exit.\n  -h, --help     Show this message and exit.\n\nCommands:\n  cite     Print the citation in the desired format\n  version  Print the version of ccbr_tools\n\nAll installed tools:\n  ccbr_tools\n  gb2gtf\n  hf\n  intersect\n  jobby\n  jobinfo\n  peek\n\n\n\nimport ccbr_tools.pkg_util\nprint(ccbr_tools.pkg_util.get_version())\n0.1.1-dev\n\n\n\n\nCommand-line utilities in CCBR Tools.\n\nccbr_tools\ngb2gtf\nhf\nintersect\njobby\njobinfo\npeek\n\nRun a command with --help to learn how to use it.\n\n\n\nAdditional standalone scripts for various common tasks in scripts/ are added to the path when this package is installed. They are less robust than the CLI Utilities included in the package and do not have any unit tests.\n\nadd_gene_name_to_count_matrix.R\naggregate_data_tables.R\nargparse.bash\ncancel_snakemake_jobs.sh\ncreate_hpc_link.sh\nextract_value_from_json.py\nextract_value_from_yaml.py\nfilter_bam_by_readids.py\nfilter_fastq_by_readids_highmem.py\nfilter_fastq_by_readids_highmem_pe.py\ngather_cluster_stats.sh\ngather_cluster_stats_biowulf.sh\nget_buyin_partition_list.bash\nget_slurm_file_with_error.sh\ngsea_preranked.sh\nkaryoploter.R\nmake_labels_for_pipeliner.sh\nrawcounts2normalizedcounts_DESeq2.R\nrawcounts2normalizedcounts_limmavoom.R\nrun_jobby_on_nextflow_log\nrun_jobby_on_nextflow_log_full_format\nrun_jobby_on_snakemake_log\nrun_jobby_on_snakemake_log_full_format\nspooker\nwhich_vpn.sh\n\n\n\n\nPlease cite this software if you use it in a publication:\n\nSovacool K., Koparde V., Kuhn S., Tandon M., Huse S. (2024). CCBR Tools: Utilities for CCBR Bioinformatics Software (version v0.1.0). DOI: 10.5281/zenodo.13377166 URL: https://ccbr.github.io/Tools/\n\n\n\n@misc{YourReferenceHere,\nauthor = {Sovacool, Kelly and Koparde, Vishal and Kuhn, Skyler and Tandon, Mayank and Huse, Susan},\ndoi = {10.5281/zenodo.13377166},\nmonth = {8},\ntitle = {CCBR Tools: Utilities for CCBR Bioinformatics Software},\nurl = {https://ccbr.github.io/Tools/},\nyear = {2024}\n}"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "CCBR Tools",
    "section": "",
    "text": "On biowulf you can access the latest release of ccbr_tools by loading the ccbrpipeliner module:\nmodule load ccbrpipeliner\nOutside of biowulf, you can install the package with pip:\npip install git+https://github.com/CCBR/Tools\nOr specify a specific tagged version or branch:\npip install git+https://github.com/CCBR/Tools@v0.1.0"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "CCBR Tools",
    "section": "",
    "text": "ccbr_tools --help\nUsage: ccbr_tools [OPTIONS] COMMAND [ARGS]...\n\n  Utilities for CCBR Bioinformatics Software\n\n  For more options, run: tool_name [command] --help\n\nOptions:\n  -v, --version  Show the version and exit.\n  -h, --help     Show this message and exit.\n\nCommands:\n  cite     Print the citation in the desired format\n  version  Print the version of ccbr_tools\n\nAll installed tools:\n  ccbr_tools\n  gb2gtf\n  hf\n  intersect\n  jobby\n  jobinfo\n  peek\n\n\n\nimport ccbr_tools.pkg_util\nprint(ccbr_tools.pkg_util.get_version())\n0.1.1-dev"
  },
  {
    "objectID": "index.html#cli-utilities",
    "href": "index.html#cli-utilities",
    "title": "CCBR Tools",
    "section": "",
    "text": "Command-line utilities in CCBR Tools.\n\nccbr_tools\ngb2gtf\nhf\nintersect\njobby\njobinfo\npeek\n\nRun a command with --help to learn how to use it."
  },
  {
    "objectID": "index.html#external-scripts",
    "href": "index.html#external-scripts",
    "title": "CCBR Tools",
    "section": "",
    "text": "Additional standalone scripts for various common tasks in scripts/ are added to the path when this package is installed. They are less robust than the CLI Utilities included in the package and do not have any unit tests.\n\nadd_gene_name_to_count_matrix.R\naggregate_data_tables.R\nargparse.bash\ncancel_snakemake_jobs.sh\ncreate_hpc_link.sh\nextract_value_from_json.py\nextract_value_from_yaml.py\nfilter_bam_by_readids.py\nfilter_fastq_by_readids_highmem.py\nfilter_fastq_by_readids_highmem_pe.py\ngather_cluster_stats.sh\ngather_cluster_stats_biowulf.sh\nget_buyin_partition_list.bash\nget_slurm_file_with_error.sh\ngsea_preranked.sh\nkaryoploter.R\nmake_labels_for_pipeliner.sh\nrawcounts2normalizedcounts_DESeq2.R\nrawcounts2normalizedcounts_limmavoom.R\nrun_jobby_on_nextflow_log\nrun_jobby_on_nextflow_log_full_format\nrun_jobby_on_snakemake_log\nrun_jobby_on_snakemake_log_full_format\nspooker\nwhich_vpn.sh"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "CCBR Tools",
    "section": "",
    "text": "Please cite this software if you use it in a publication:\n\nSovacool K., Koparde V., Kuhn S., Tandon M., Huse S. (2024). CCBR Tools: Utilities for CCBR Bioinformatics Software (version v0.1.0). DOI: 10.5281/zenodo.13377166 URL: https://ccbr.github.io/Tools/\n\n\n\n@misc{YourReferenceHere,\nauthor = {Sovacool, Kelly and Koparde, Vishal and Kuhn, Skyler and Tandon, Mayank and Huse, Susan},\ndoi = {10.5281/zenodo.13377166},\nmonth = {8},\ntitle = {CCBR Tools: Utilities for CCBR Bioinformatics Software},\nurl = {https://ccbr.github.io/Tools/},\nyear = {2024}\n}"
  },
  {
    "objectID": "reference/shell.html",
    "href": "reference/shell.html",
    "title": "shell",
    "section": "",
    "text": "shell\nUtility functions for shell command execution.\n\n\n\n\n\nshell_run(“echo Hello, World!”) ’Hello, World!\n\n\n\n’ &gt;&gt;&gt; shell_run(“invalid_command”) ‘/bin/sh: invalid_command: command not found’\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nconcat_newline\nConcatenates strings with a newline character between non-empty arguments\n\n\nexec_in_context\nExecutes a function in a context manager and captures the output from stdout and stderr.\n\n\nshell_run\nRun a shell command and return stdout/stderr\n\n\n\n\n\nshell.concat_newline(*args)\nConcatenates strings with a newline character between non-empty arguments\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n*args\nstr\nVariable length argument list of strings to be concatenated.\n()\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nThe concatenated string with newline characters between each non-empty argument.\n\n\n\n\n\n\n\nshell.exec_in_context(func, *args, **kwargs)\nExecutes a function in a context manager and captures the output from stdout and stderr.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfunc\nfunc\nThe function to be executed.\nrequired\n\n\n*args\nstr\nVariable length argument list to be passed to the function.\n()\n\n\n**kwargs\nstr\nArbitrary keyword arguments to be passed to the function.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nThe combined output from both stdout and stderr.\n\n\n\n\n\n\n\nshell.shell_run(command_str, capture_output=True, check=True, shell=True, text=True)\nRun a shell command and return stdout/stderr\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncommand_str\nstr\nThe shell command to be executed.\nrequired\n\n\ncapture_output\nbool\nWhether to capture the command’s output. Defaults to True.\nTrue\n\n\ncheck\nbool\nWhether to raise an exception if the command returns a non-zero exit status. Defaults to True.\nTrue\n\n\nshell\nbool\nWhether to run the command through the shell. Defaults to True.\nTrue\n\n\ntext\nbool\nWhether to treat the command’s input/output as text. Defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe combined stdout and stderr of the command, separated by a newline character.",
    "crumbs": [
      "Reference",
      "Modules",
      "shell"
    ]
  },
  {
    "objectID": "reference/shell.html#example",
    "href": "reference/shell.html#example",
    "title": "shell",
    "section": "",
    "text": "shell_run(“echo Hello, World!”) ’Hello, World!\n\n\n\n’ &gt;&gt;&gt; shell_run(“invalid_command”) ‘/bin/sh: invalid_command: command not found’",
    "crumbs": [
      "Reference",
      "Modules",
      "shell"
    ]
  },
  {
    "objectID": "reference/shell.html#functions",
    "href": "reference/shell.html#functions",
    "title": "shell",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nconcat_newline\nConcatenates strings with a newline character between non-empty arguments\n\n\nexec_in_context\nExecutes a function in a context manager and captures the output from stdout and stderr.\n\n\nshell_run\nRun a shell command and return stdout/stderr\n\n\n\n\n\nshell.concat_newline(*args)\nConcatenates strings with a newline character between non-empty arguments\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n*args\nstr\nVariable length argument list of strings to be concatenated.\n()\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nThe concatenated string with newline characters between each non-empty argument.\n\n\n\n\n\n\n\nshell.exec_in_context(func, *args, **kwargs)\nExecutes a function in a context manager and captures the output from stdout and stderr.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfunc\nfunc\nThe function to be executed.\nrequired\n\n\n*args\nstr\nVariable length argument list to be passed to the function.\n()\n\n\n**kwargs\nstr\nArbitrary keyword arguments to be passed to the function.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nThe combined output from both stdout and stderr.\n\n\n\n\n\n\n\nshell.shell_run(command_str, capture_output=True, check=True, shell=True, text=True)\nRun a shell command and return stdout/stderr\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncommand_str\nstr\nThe shell command to be executed.\nrequired\n\n\ncapture_output\nbool\nWhether to capture the command’s output. Defaults to True.\nTrue\n\n\ncheck\nbool\nWhether to raise an exception if the command returns a non-zero exit status. Defaults to True.\nTrue\n\n\nshell\nbool\nWhether to run the command through the shell. Defaults to True.\nTrue\n\n\ntext\nbool\nWhether to treat the command’s input/output as text. Defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe combined stdout and stderr of the command, separated by a newline character.",
    "crumbs": [
      "Reference",
      "Modules",
      "shell"
    ]
  },
  {
    "objectID": "reference/pkg_util.html",
    "href": "reference/pkg_util.html",
    "title": "pkg_util",
    "section": "",
    "text": "pkg_util\nMiscellaneous utility functions for the package\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_external_scripts\nGet list of standalone scripts included in the package\n\n\nget_package_version\nGet the current version of a package from the metadata.\n\n\nget_project_scripts\nGet a list of CLI tools in the package.\n\n\nget_pyproject_toml\nGet the contents of the package’s pyproject.toml file.\n\n\nget_version\nGet the current version of the ccbr_tools package.\n\n\nmsg\nPrints the error message with a timestamp.\n\n\nmsg_box\nDisplays a message box with a given splash message.\n\n\nprint_citation\nPrints the citation for the given citation file in the specified output format.\n\n\nread_template\nRead a template file\n\n\nrepo_base\nGet the absolute path to a file in the repository\n\n\nuse_template\nUses a template, formats variables, and writes it to a file.\n\n\n\n\n\npkg_util.get_external_scripts(pkg_name='ccbr_tools')\nGet list of standalone scripts included in the package\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nThe name of the package. Defaults to “ccbr_tools”.\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of standalone scripts included in the package.\n\n\n\n\n\n\n\npkg_util.get_package_version(pkg_name='ccbr_tools')\nGet the current version of a package from the metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nName of the package (default: ccbr_tools).\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe version of the package.\n\n\n\n\n\n\n\npkg_util.get_project_scripts(pkg_name='ccbr_tools')\nGet a list of CLI tools in the package.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nThe name of the package. Defaults to “ccbr_tools”.\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA sorted list of CLI tool names.\n\n\n\n\n\n\n\npkg_util.get_pyproject_toml(pkg_name='ccbr_tools', repo_base=repo_base)\nGet the contents of the package’s pyproject.toml file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nName of the package (default: ccbr_tools).\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndict\nThe contents of the pyproject.toml file.\n\n\n\n\n\n\n\npkg_util.get_version(repo_base=repo_base, debug=False)\nGet the current version of the ccbr_tools package.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nrepo_base\nfunction\nA function that returns the base path of the repository.\nrepo_base\n\n\ndebug\nbool\nPrint the path to the VERSION file (default: False).\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe version of the package.\n\n\n\n\n\n\n\npkg_util.msg(err_message)\nPrints the error message with a timestamp.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nerr_message\nstr\nThe error message to be printed.\nrequired\n\n\n\nReturns: None\n\n\n\n\npkg_util.msg_box(splash, errmsg=None)\nDisplays a message box with a given splash message.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsplash\nstr\nThe splash message to be displayed.\nrequired\n\n\nerrmsg\nstr\nAn error message to be displayed below the splash message. Defaults to None.\nNone\n\n\n\n\n\n\n\npkg_util.print_citation(citation_file=repo_base('CITATION.cff'), output_format='bibtex')\nPrints the citation for the given citation file in the specified output format.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncitation_file\nstr\nThe path to the citation file.\nrepo_base('CITATION.cff')\n\n\noutput_format\nstr\nThe desired output format for the citation.\n'bibtex'\n\n\n\n\n\n\n\npkg_util.read_template(template_name)\nRead a template file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntemplate_name\nstr\nName of the template file\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nContents of the template file\n\n\n\n\n\n\n\npkg_util.repo_base(*paths)\nGet the absolute path to a file in the repository\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n*paths\nstr\nAdditional paths to join with the base path.\n()\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe absolute path to the file in the repository.\n\n\n\n\n\n\n\npkg_util.use_template(template_name, output_filepath=None, **kwargs)\nUses a template, formats variables, and writes it to a file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntemplate_name\nstr\nThe name of the template to use.\nrequired\n\n\noutput_filepath\nstr\nThe filepath to save the output file. If not provided, it will be written to template_name in the current working directory.\nNone\n\n\n**kwargs\n\nKeyword arguments to fill in the template variables.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFileNotFoundError\nIf the template file is not found.\n\n\nIOError\nIf there is an error writing the output file.\n\n\n\n\n\n\nuse_template(“slurm_nxf_biowulf.sh”, output_filepath=“submit_slurm.sh”, PIPELINE=“CCBR_nxf”, RUN_COMMAND=“nextflow run main.nf -stub”)",
    "crumbs": [
      "Reference",
      "Modules",
      "pkg_util"
    ]
  },
  {
    "objectID": "reference/pkg_util.html#functions",
    "href": "reference/pkg_util.html#functions",
    "title": "pkg_util",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_external_scripts\nGet list of standalone scripts included in the package\n\n\nget_package_version\nGet the current version of a package from the metadata.\n\n\nget_project_scripts\nGet a list of CLI tools in the package.\n\n\nget_pyproject_toml\nGet the contents of the package’s pyproject.toml file.\n\n\nget_version\nGet the current version of the ccbr_tools package.\n\n\nmsg\nPrints the error message with a timestamp.\n\n\nmsg_box\nDisplays a message box with a given splash message.\n\n\nprint_citation\nPrints the citation for the given citation file in the specified output format.\n\n\nread_template\nRead a template file\n\n\nrepo_base\nGet the absolute path to a file in the repository\n\n\nuse_template\nUses a template, formats variables, and writes it to a file.\n\n\n\n\n\npkg_util.get_external_scripts(pkg_name='ccbr_tools')\nGet list of standalone scripts included in the package\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nThe name of the package. Defaults to “ccbr_tools”.\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of standalone scripts included in the package.\n\n\n\n\n\n\n\npkg_util.get_package_version(pkg_name='ccbr_tools')\nGet the current version of a package from the metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nName of the package (default: ccbr_tools).\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe version of the package.\n\n\n\n\n\n\n\npkg_util.get_project_scripts(pkg_name='ccbr_tools')\nGet a list of CLI tools in the package.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nThe name of the package. Defaults to “ccbr_tools”.\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA sorted list of CLI tool names.\n\n\n\n\n\n\n\npkg_util.get_pyproject_toml(pkg_name='ccbr_tools', repo_base=repo_base)\nGet the contents of the package’s pyproject.toml file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npkg_name\nstr\nName of the package (default: ccbr_tools).\n'ccbr_tools'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ndict\nThe contents of the pyproject.toml file.\n\n\n\n\n\n\n\npkg_util.get_version(repo_base=repo_base, debug=False)\nGet the current version of the ccbr_tools package.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nrepo_base\nfunction\nA function that returns the base path of the repository.\nrepo_base\n\n\ndebug\nbool\nPrint the path to the VERSION file (default: False).\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe version of the package.\n\n\n\n\n\n\n\npkg_util.msg(err_message)\nPrints the error message with a timestamp.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nerr_message\nstr\nThe error message to be printed.\nrequired\n\n\n\nReturns: None\n\n\n\n\npkg_util.msg_box(splash, errmsg=None)\nDisplays a message box with a given splash message.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsplash\nstr\nThe splash message to be displayed.\nrequired\n\n\nerrmsg\nstr\nAn error message to be displayed below the splash message. Defaults to None.\nNone\n\n\n\n\n\n\n\npkg_util.print_citation(citation_file=repo_base('CITATION.cff'), output_format='bibtex')\nPrints the citation for the given citation file in the specified output format.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncitation_file\nstr\nThe path to the citation file.\nrepo_base('CITATION.cff')\n\n\noutput_format\nstr\nThe desired output format for the citation.\n'bibtex'\n\n\n\n\n\n\n\npkg_util.read_template(template_name)\nRead a template file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntemplate_name\nstr\nName of the template file\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nContents of the template file\n\n\n\n\n\n\n\npkg_util.repo_base(*paths)\nGet the absolute path to a file in the repository\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n*paths\nstr\nAdditional paths to join with the base path.\n()\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nstr\nThe absolute path to the file in the repository.\n\n\n\n\n\n\n\npkg_util.use_template(template_name, output_filepath=None, **kwargs)\nUses a template, formats variables, and writes it to a file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntemplate_name\nstr\nThe name of the template to use.\nrequired\n\n\noutput_filepath\nstr\nThe filepath to save the output file. If not provided, it will be written to template_name in the current working directory.\nNone\n\n\n**kwargs\n\nKeyword arguments to fill in the template variables.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFileNotFoundError\nIf the template file is not found.\n\n\nIOError\nIf there is an error writing the output file.\n\n\n\n\n\n\nuse_template(“slurm_nxf_biowulf.sh”, output_filepath=“submit_slurm.sh”, PIPELINE=“CCBR_nxf”, RUN_COMMAND=“nextflow run main.nf -stub”)",
    "crumbs": [
      "Reference",
      "Modules",
      "pkg_util"
    ]
  },
  {
    "objectID": "reference/pipeline.html",
    "href": "reference/pipeline.html",
    "title": "pipeline",
    "section": "",
    "text": "pipeline\npipeline",
    "crumbs": [
      "Reference",
      "Modules",
      "pipeline"
    ]
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing to CCBR Tools",
    "section": "",
    "text": "If you want to make a change, it’s a good idea to first open an issue and make sure someone from the team agrees that it’s needed.\nIf you’ve decided to work on an issue, assign yourself to the issue so others will know you’re working on it.\n\n\n\nWe use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to CCBR Tools.\n\n\n\nGitHub Flow diagram\n\n\n\n\nIf you are a member of CCBR, you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once.\ngit clone https://github.com/CCBR/tools\n\nCloning into ‘tools’…  remote: Enumerating objects: 1136, done.  remote: Counting objects: 100% (463/463), done.  remote: Compressing objects: 100% (357/357), done.  remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673  Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done.  Resolving deltas: 100% (530/530), done. \n\ncd tools\n\n\n\n\nInstall the python dependencies with pip\npip install .[[dev,test]]\nInstall pre-commit if you don’t already have it. Then from the repo’s root directory, run\npre-commit install\nThis will install the repo’s pre-commit hooks. You’ll only need to do this step the first time you clone the repo.\n\n\n\n\nCreate a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue.\n# create a new branch and switch to it\ngit branch iss-10\ngit switch iss-10\n\nSwitched to a new branch ‘iss-10’\n\n\n\n\nEdit the code, write and run tests, and update the documentation as needed.\n\n\nChanges to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest.\n\n\n\nIf you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/. If the changes are in src/, you may need to update the docstrings – we use Google Style for Python code.\n\n\n\n\nIf you’re not sure how often you should commit or what your commits should consist of, we recommend following the “atomic commits” principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/\nFirst, add the files that you changed to the staging area:\ngit add path/to/changed/files/\nThen make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat, fix, docs, etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages.\ngit commit -m 'feat: create function for awesome feature'\npre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed.\n\nCheck for added large files……………………………………….Passed  Fix End of Files…………………………………………………Passed  Trim Trailing Whitespace………………………………………….Failed \n\nhook id: trailing-whitespace \nexit code: 1 \nfiles were modified by this hook  &gt;  Fixing path/to/changed/files/file.txt  &gt;  codespell……………………………………………………….Passed  style-files……………………………………(no files to check)Skipped  readme-rmd-rendered…………………………….(no files to check)Skipped  use-tidy-description……………………………(no files to check)Skipped \n\n\nIn the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command:\ngit add path/to/changed/files/file.txt\ngit commit -m 'feat: create function for awesome feature'\nThis time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created.\n\nCheck for added large files……………………………………….Passed  Fix End of Files…………………………………………………Passed  Trim Trailing Whitespace………………………………………….Passed  codespell……………………………………………………….Passed  style-files……………………………………(no files to check)Skipped  readme-rmd-rendered…………………………….(no files to check)Skipped  use-tidy-description……………………………(no files to check)Skipped  Conventional Commit………………………………………………Passed  &gt; [iss-10 9ff256e] feat: create function for awesome feature  1 file changed, 22 insertions(+), 3 deletions(-) \n\nFinally, push your changes to GitHub:\ngit push\nIf this is the first time you are pushing this branch, you may have to explicitly set the upstream branch:\ngit push --set-upstream origin iss-10\n\nEnumerating objects: 7, done.  Counting objects: 100% (7/7), done.  Delta compression using up to 10 threads  Compressing objects: 100% (4/4), done.  Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done.  Total 4 (delta 3), reused 0 (delta 0), pack-reused 0  remote: Resolving deltas: 100% (3/3), completed with 3 local objects.  remote:  remote: Create a pull request for ‘iss-10’ on GitHub by visiting:  remote: https://github.com/CCBR/tools/pull/new/iss-10  remote:  To https://github.com/CCBR/tools  &gt;  &gt; [new branch] iss-10 -&gt; iss-10  branch ‘iss-10’ set up to track ‘origin/iss-10’. \n\nWe recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/tools/tree/&lt;your-branch-name&gt; (replace &lt;your-branch-name&gt; with the actual name of your branch).\n\n\n\nOnce your branch is ready, create a PR on GitHub: https://github.com/CCBR/tools/pull/new/\nSelect the branch you just pushed:\n\n\n\nCreate a new PR from your branch\n\n\nEdit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between &lt;!-- and --&gt;) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you’re ready, click ‘Create pull request’ to open it.\n\n\n\nOpen the PR after editing the title and description\n\n\nOptionally, you can mark the PR as a draft if you’re not yet ready for it to be reviewed, then change it later when you’re ready.\n\n\n\nWe will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/. The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that’s the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR.\nOnce the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!\n\n\n\nAfter your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes:\ngit checkout main\ngit pull\nIt’s a good idea to run git pull before creating a new branch so it will start from the most recent commits in main.\n\n\n\n\n\nGitHub Flow\nsemantic versioning guidelines\nchangelog guidelines\ntidyverse code review principles\nreproducible examples"
  },
  {
    "objectID": "CONTRIBUTING.html#proposing-changes-with-issues",
    "href": "CONTRIBUTING.html#proposing-changes-with-issues",
    "title": "Contributing to CCBR Tools",
    "section": "",
    "text": "If you want to make a change, it’s a good idea to first open an issue and make sure someone from the team agrees that it’s needed.\nIf you’ve decided to work on an issue, assign yourself to the issue so others will know you’re working on it."
  },
  {
    "objectID": "CONTRIBUTING.html#pull-request-process",
    "href": "CONTRIBUTING.html#pull-request-process",
    "title": "Contributing to CCBR Tools",
    "section": "",
    "text": "We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to CCBR Tools.\n\n\n\nGitHub Flow diagram\n\n\n\n\nIf you are a member of CCBR, you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once.\ngit clone https://github.com/CCBR/tools\n\nCloning into ‘tools’…  remote: Enumerating objects: 1136, done.  remote: Counting objects: 100% (463/463), done.  remote: Compressing objects: 100% (357/357), done.  remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673  Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done.  Resolving deltas: 100% (530/530), done. \n\ncd tools\n\n\n\n\nInstall the python dependencies with pip\npip install .[[dev,test]]\nInstall pre-commit if you don’t already have it. Then from the repo’s root directory, run\npre-commit install\nThis will install the repo’s pre-commit hooks. You’ll only need to do this step the first time you clone the repo.\n\n\n\n\nCreate a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue.\n# create a new branch and switch to it\ngit branch iss-10\ngit switch iss-10\n\nSwitched to a new branch ‘iss-10’\n\n\n\n\nEdit the code, write and run tests, and update the documentation as needed.\n\n\nChanges to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest.\n\n\n\nIf you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/. If the changes are in src/, you may need to update the docstrings – we use Google Style for Python code.\n\n\n\n\nIf you’re not sure how often you should commit or what your commits should consist of, we recommend following the “atomic commits” principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/\nFirst, add the files that you changed to the staging area:\ngit add path/to/changed/files/\nThen make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat, fix, docs, etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages.\ngit commit -m 'feat: create function for awesome feature'\npre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed.\n\nCheck for added large files……………………………………….Passed  Fix End of Files…………………………………………………Passed  Trim Trailing Whitespace………………………………………….Failed \n\nhook id: trailing-whitespace \nexit code: 1 \nfiles were modified by this hook  &gt;  Fixing path/to/changed/files/file.txt  &gt;  codespell……………………………………………………….Passed  style-files……………………………………(no files to check)Skipped  readme-rmd-rendered…………………………….(no files to check)Skipped  use-tidy-description……………………………(no files to check)Skipped \n\n\nIn the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command:\ngit add path/to/changed/files/file.txt\ngit commit -m 'feat: create function for awesome feature'\nThis time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created.\n\nCheck for added large files……………………………………….Passed  Fix End of Files…………………………………………………Passed  Trim Trailing Whitespace………………………………………….Passed  codespell……………………………………………………….Passed  style-files……………………………………(no files to check)Skipped  readme-rmd-rendered…………………………….(no files to check)Skipped  use-tidy-description……………………………(no files to check)Skipped  Conventional Commit………………………………………………Passed  &gt; [iss-10 9ff256e] feat: create function for awesome feature  1 file changed, 22 insertions(+), 3 deletions(-) \n\nFinally, push your changes to GitHub:\ngit push\nIf this is the first time you are pushing this branch, you may have to explicitly set the upstream branch:\ngit push --set-upstream origin iss-10\n\nEnumerating objects: 7, done.  Counting objects: 100% (7/7), done.  Delta compression using up to 10 threads  Compressing objects: 100% (4/4), done.  Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done.  Total 4 (delta 3), reused 0 (delta 0), pack-reused 0  remote: Resolving deltas: 100% (3/3), completed with 3 local objects.  remote:  remote: Create a pull request for ‘iss-10’ on GitHub by visiting:  remote: https://github.com/CCBR/tools/pull/new/iss-10  remote:  To https://github.com/CCBR/tools  &gt;  &gt; [new branch] iss-10 -&gt; iss-10  branch ‘iss-10’ set up to track ‘origin/iss-10’. \n\nWe recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/tools/tree/&lt;your-branch-name&gt; (replace &lt;your-branch-name&gt; with the actual name of your branch).\n\n\n\nOnce your branch is ready, create a PR on GitHub: https://github.com/CCBR/tools/pull/new/\nSelect the branch you just pushed:\n\n\n\nCreate a new PR from your branch\n\n\nEdit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between &lt;!-- and --&gt;) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you’re ready, click ‘Create pull request’ to open it.\n\n\n\nOpen the PR after editing the title and description\n\n\nOptionally, you can mark the PR as a draft if you’re not yet ready for it to be reviewed, then change it later when you’re ready.\n\n\n\nWe will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/. The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that’s the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR.\nOnce the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!\n\n\n\nAfter your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes:\ngit checkout main\ngit pull\nIt’s a good idea to run git pull before creating a new branch so it will start from the most recent commits in main."
  },
  {
    "objectID": "CONTRIBUTING.html#helpful-links-for-more-information",
    "href": "CONTRIBUTING.html#helpful-links-for-more-information",
    "title": "Contributing to CCBR Tools",
    "section": "",
    "text": "GitHub Flow\nsemantic versioning guidelines\nchangelog guidelines\ntidyverse code review principles\nreproducible examples"
  }
]